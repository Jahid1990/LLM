{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-30T07:35:26.545676Z","iopub.execute_input":"2023-09-30T07:35:26.546037Z","iopub.status.idle":"2023-09-30T07:35:26.551046Z","shell.execute_reply.started":"2023-09-30T07:35:26.546010Z","shell.execute_reply":"2023-09-30T07:35:26.549896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport librosa\n\naudio_dataset_path='/kaggle/input/bengaliai-speech/train_mp3s/'\nmetadata=pd.read_csv('/kaggle/input/bengaliai-speech/train.csv')\nmetadata['path']=[x for x in audio_dataset_path+metadata.id+'.mp3']","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:26.572217Z","iopub.execute_input":"2023-09-30T07:35:26.572797Z","iopub.status.idle":"2023-09-30T07:35:32.559225Z","shell.execute_reply.started":"2023-09-30T07:35:26.572766Z","shell.execute_reply":"2023-09-30T07:35:32.557993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def features_extractor(file):\n#     audio, sample_rate = librosa.load(file_name) \n#     mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n#     mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    \n#     return mfccs_scaled_features\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:32.561013Z","iopub.execute_input":"2023-09-30T07:35:32.561510Z","iopub.status.idle":"2023-09-30T07:35:32.565068Z","shell.execute_reply.started":"2023-09-30T07:35:32.561481Z","shell.execute_reply":"2023-09-30T07:35:32.563960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from tqdm import tqdm\n# ### Now we iterate through every audio file and extract features \n# ### using Mel-Frequency Cepstral Coefficients\n# extracted_features=[]\n# for index_num,row in tqdm(metadata.iterrows()):\n#     file_name = os.path.join(os.path.abspath(audio_dataset_path)+'/'+str(row[\"id\"])+'.mp3')\n#     final_class_labels=row[\"sentence\"]\n#     data=features_extractor(file_name)\n#     extracted_features.append([file_name,data,final_class_labels])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:32.566299Z","iopub.execute_input":"2023-09-30T07:35:32.566648Z","iopub.status.idle":"2023-09-30T07:35:32.590112Z","shell.execute_reply.started":"2023-09-30T07:35:32.566620Z","shell.execute_reply":"2023-09-30T07:35:32.589039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extracted_features_df=pd.DataFrame(extracted_features,columns=['path','feature','label'])\n# extracted_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:32.592809Z","iopub.execute_input":"2023-09-30T07:35:32.593506Z","iopub.status.idle":"2023-09-30T07:35:32.606259Z","shell.execute_reply.started":"2023-09-30T07:35:32.593464Z","shell.execute_reply":"2023-09-30T07:35:32.605380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset,load_metric,DatasetDict\n\nmetadata.iloc[:100,:].to_csv('metadata.csv',sep=',',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:32.607430Z","iopub.execute_input":"2023-09-30T07:35:32.607749Z","iopub.status.idle":"2023-09-30T07:35:33.497207Z","shell.execute_reply.started":"2023-09-30T07:35:32.607722Z","shell.execute_reply":"2023-09-30T07:35:33.496033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=DatasetDict()\ndataset=load_dataset('/kaggle/working',split='train')","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:33.498533Z","iopub.execute_input":"2023-09-30T07:35:33.498880Z","iopub.status.idle":"2023-09-30T07:35:34.832189Z","shell.execute_reply.started":"2023-09-30T07:35:33.498853Z","shell.execute_reply":"2023-09-30T07:35:34.831274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=dataset.remove_columns(['id','split'])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:34.833156Z","iopub.execute_input":"2023-09-30T07:35:34.833469Z","iopub.status.idle":"2023-09-30T07:35:34.843433Z","shell.execute_reply.started":"2023-09-30T07:35:34.833443Z","shell.execute_reply":"2023-09-30T07:35:34.840377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:34.845148Z","iopub.execute_input":"2023-09-30T07:35:34.845605Z","iopub.status.idle":"2023-09-30T07:35:34.860149Z","shell.execute_reply.started":"2023-09-30T07:35:34.845526Z","shell.execute_reply":"2023-09-30T07:35:34.858598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import WhisperFeatureExtractor\n\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:34.861621Z","iopub.execute_input":"2023-09-30T07:35:34.862634Z","iopub.status.idle":"2023-09-30T07:35:38.697596Z","shell.execute_reply.started":"2023-09-30T07:35:34.862591Z","shell.execute_reply":"2023-09-30T07:35:38.696287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import WhisperTokenizer\n\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"bengali\", task=\"transcribe\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:38.701259Z","iopub.execute_input":"2023-09-30T07:35:38.702041Z","iopub.status.idle":"2023-09-30T07:35:44.425669Z","shell.execute_reply.started":"2023-09-30T07:35:38.702007Z","shell.execute_reply":"2023-09-30T07:35:44.424642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_str = dataset[\"sentence\"][0]\nlabels = tokenizer(input_str).input_ids\ndecoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\ndecoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n\nprint(f\"Input:                 {input_str}\")\nprint(f\"Decoded w/ special:    {decoded_with_special}\")\nprint(f\"Decoded w/out special: {decoded_str}\")\nprint(f\"Are equal:             {input_str == decoded_str}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:44.427028Z","iopub.execute_input":"2023-09-30T07:35:44.427374Z","iopub.status.idle":"2023-09-30T07:35:54.788649Z","shell.execute_reply.started":"2023-09-30T07:35:44.427301Z","shell.execute_reply":"2023-09-30T07:35:54.787520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import WhisperProcessor\n\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"bengali\", task=\"transcribe\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:54.789800Z","iopub.execute_input":"2023-09-30T07:35:54.790479Z","iopub.status.idle":"2023-09-30T07:35:55.379160Z","shell.execute_reply.started":"2023-09-30T07:35:54.790450Z","shell.execute_reply":"2023-09-30T07:35:55.377916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Audio\n\ncommon_voice = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n#common_voice['audio']#=common_voice.remove_columns(['feature'])","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:55.380776Z","iopub.execute_input":"2023-09-30T07:35:55.381499Z","iopub.status.idle":"2023-09-30T07:35:55.434988Z","shell.execute_reply.started":"2023-09-30T07:35:55.381468Z","shell.execute_reply":"2023-09-30T07:35:55.434209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(batch):\n    # load and resample audio data from 48 to 16kHz\n    audio = batch[\"path\"]\n\n    # compute log-Mel input features from input audio array \n    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n\n    # encode target text to label ids \n    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:55.436468Z","iopub.execute_input":"2023-09-30T07:35:55.437104Z","iopub.status.idle":"2023-09-30T07:35:55.443092Z","shell.execute_reply.started":"2023-09-30T07:35:55.437067Z","shell.execute_reply":"2023-09-30T07:35:55.441896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"common_voice = common_voice.map(prepare_dataset, num_proc=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:35:55.444221Z","iopub.execute_input":"2023-09-30T07:35:55.444561Z","iopub.status.idle":"2023-09-30T07:36:18.549096Z","shell.execute_reply.started":"2023-09-30T07:35:55.444518Z","shell.execute_reply":"2023-09-30T07:36:18.548020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common_voice['input_features']","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:18.551455Z","iopub.execute_input":"2023-09-30T07:36:18.551804Z","iopub.status.idle":"2023-09-30T07:36:18.556269Z","shell.execute_reply.started":"2023-09-30T07:36:18.551777Z","shell.execute_reply":"2023-09-30T07:36:18.555161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:18.557723Z","iopub.execute_input":"2023-09-30T07:36:18.558401Z","iopub.status.idle":"2023-09-30T07:36:18.933596Z","shell.execute_reply.started":"2023-09-30T07:36:18.558361Z","shell.execute_reply":"2023-09-30T07:36:18.932367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:18.935443Z","iopub.execute_input":"2023-09-30T07:36:18.936287Z","iopub.status.idle":"2023-09-30T07:36:18.953275Z","shell.execute_reply.started":"2023-09-30T07:36:18.936245Z","shell.execute_reply":"2023-09-30T07:36:18.952424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate\n!pip install jiwer\nimport evaluate\nmetric = evaluate.load(\"wer\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:18.954639Z","iopub.execute_input":"2023-09-30T07:36:18.954944Z","iopub.status.idle":"2023-09-30T07:36:46.045684Z","shell.execute_reply.started":"2023-09-30T07:36:18.954918Z","shell.execute_reply":"2023-09-30T07:36:46.044760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    # we do not want to group tokens when computing the metrics\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:46.049148Z","iopub.execute_input":"2023-09-30T07:36:46.049516Z","iopub.status.idle":"2023-09-30T07:36:46.056622Z","shell.execute_reply.started":"2023-09-30T07:36:46.049488Z","shell.execute_reply":"2023-09-30T07:36:46.054892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:36:46.058363Z","iopub.execute_input":"2023-09-30T07:36:46.059089Z","iopub.status.idle":"2023-09-30T07:37:40.488780Z","shell.execute_reply.started":"2023-09-30T07:36:46.059047Z","shell.execute_reply":"2023-09-30T07:37:40.487724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.forced_decoder_ids = None\nmodel.config.suppress_tokens = []","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:37:40.490339Z","iopub.execute_input":"2023-09-30T07:37:40.490682Z","iopub.status.idle":"2023-09-30T07:37:40.495335Z","shell.execute_reply.started":"2023-09-30T07:37:40.490654Z","shell.execute_reply":"2023-09-30T07:37:40.494389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-small-bn\",  # change to a repo name of your choice\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n    learning_rate=1e-5,\n    warmup_steps=500,\n    max_steps=4000,\n    gradient_checkpointing=True,\n    #fp16=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=1000,\n    eval_steps=1000,\n    logging_steps=25,\n    #report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:37:40.496927Z","iopub.execute_input":"2023-09-30T07:37:40.497263Z","iopub.status.idle":"2023-09-30T07:37:40.530883Z","shell.execute_reply.started":"2023-09-30T07:37:40.497236Z","shell.execute_reply":"2023-09-30T07:37:40.529723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=common_voice,\n    eval_dataset=common_voice,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:37:40.532250Z","iopub.execute_input":"2023-09-30T07:37:40.532809Z","iopub.status.idle":"2023-09-30T07:37:40.574279Z","shell.execute_reply.started":"2023-09-30T07:37:40.532775Z","shell.execute_reply":"2023-09-30T07:37:40.573168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T07:37:40.575871Z","iopub.execute_input":"2023-09-30T07:37:40.576170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport numpy as np\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\nlabels = tokenizer(extracted_features_df['sentence'].to_list(), return_tensors=\"np\", padding=True)\n# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n\n# labels = dict(tokenized_data)\n# #labels = np.array(dataset[\"sentence\"])\ntrainx=np.array(extracted_features_df['feature'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification\nfrom tensorflow.keras.optimizers import Adam\n\n# Load and compile our model\nmodel = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n# Lower learning rates are often better for fine-tuning transformers\nmodel.compile(optimizer=Adam(3e-5))  # No loss argument!\n\nmodel.fit(trainx, labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndataset = dataset.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length'), batched=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.remove_columns(['sentence'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# from transformers import TFAutoModelForSequenceClassification\n\n# model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\nfrom transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",output_attentions=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install jiwer\nimport jiwer\nwer_metric = load_metric(\"wer\")\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = tokenizer.pad_token_id\n\n    pred_str = tokenizer.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = tokenizer.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset,\n    eval_dataset=dataset,\n    #compute_metrics=compute_metrics,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TF","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification\n\nmodel = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_dataset(data):\n    return tokenizer(data[\"text\"],return_tensors=\"np\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"rotten_tomatoes\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(tokenize_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['train']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_dataset = model.prepare_tf_dataset(\n    dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer\n)  # doctest: +SKIP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n#model.compile(optimizer=Adam(3e-5))  # No loss argument!\nmodel.fit(common_voice['input_features'],common_voice['labels'])  # doctest: +SKIP","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}